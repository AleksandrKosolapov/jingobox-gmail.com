{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 2:\n",
    "При покупке авиабилета пользователям предлагаются дополнительные услуги (страховка, онлайн-регистрация, выбор места, и т.д.). Для каждого заказа определите вероятность покупки каждой дополнительной услуги. В качестве сабмита принимается .csv файл с шестью колонками - id заказа (orderid) и вероятность покупки пяти дополнительных услуг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('onetwotrip_challenge_train.csv')\n",
    "test = pd.read_csv('onetwotrip_challenge_test.csv')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(pd.concat([train['userid'],test['userid']]))\n",
    "train['userid'] = le.transform(train['userid'])\n",
    "test['userid'] = le.transform(test['userid'])\n",
    "\n",
    "train['COUNT_id'] = train['userid'].map(train['userid'].value_counts())\n",
    "test['COUNT_id'] = test['userid'].map(test['userid'].value_counts())\n",
    "\n",
    "fichi = [c for c in train.columns if c not in ['goal21', 'goal22', 'goal23', 'goal24', 'goal25', 'goal1','orderid','userid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique14 = np.unique(pd.concat([train['field14'],test['field14']]))\n",
    "new_unique14 = np.round(unique14 / 0.14006639 - 0.27860731).astype(int)\n",
    "dict14 = {unique14[i]: new_unique14[i] for i in range(len(unique14))}\n",
    "train['field14'] = train['field14'].apply(lambda x: dict14[x])\n",
    "test['field14'] = test['field14'].apply(lambda x: dict14[x])\n",
    "\n",
    "train['field14'] = train['field14'] + np.absolute(pd.concat([train['field14'],test['field14']]).min())\n",
    "test['field14'] = test['field14'] + np.absolute(pd.concat([train['field14'],test['field14']]).min())\n",
    "\n",
    "unique1 = np.unique(pd.concat([train['field1'],test['field1']]))\n",
    "new_unique1 = np.round(unique1  / 0.077571 + 0.0765905).astype(int)\n",
    "dict1 = {unique1[i]: new_unique1[i] for i in range(len(unique1))}\n",
    "train['field1'] = train['field1'].apply(lambda x: dict1[x])\n",
    "test['field1'] = test['field1'].apply(lambda x: dict1[x])        \n",
    "        \n",
    "train['field1'] = train['field1'] + np.absolute(pd.concat([train['field1'],test['field1']]).min())\n",
    "test['field1'] = test['field1'] + np.absolute(pd.concat([train['field1'],test['field1']]).min())\n",
    "\n",
    "train['ticket_price'] = train['field1'] / train['field15']\n",
    "test['ticket_price'] = test['field1'] / test['field15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp\n",
    "features = [c for c in train.columns if c not in ['goal21', 'goal22', 'goal23', 'goal24', 'goal25', 'goal1','orderid','userid']]\n",
    "for f in features:\n",
    "    train['COUNT_{}'.format(f)] = train[f].map(pd.concat([train[f],test[f]]).value_counts())\n",
    "    test['COUNT_{}'.format(f)] = test[f].map(pd.concat([train[f],test[f]]).value_counts())\n",
    "for df in [train,test]:\n",
    "    for f in features:\n",
    "        df['{}_STD'.format(f)] = df['userid'].map(pd.concat([train[['userid',f]],test[['userid',f]]]).groupby('userid')[f].std())\n",
    "        df['{}_MEAN'.format(f)] = df['userid'].map(pd.concat([train[['userid',f]],test[['userid',f]]]).groupby('userid')[f].mean())\n",
    "        df['{}_MAX'.format(f)] = df['userid'].map(pd.concat([train[['userid',f]],test[['userid',f]]]).groupby('userid')[f].max())\n",
    "        df['{}_MIN'.format(f)] = df['userid'].map(pd.concat([train[['userid',f]],test[['userid',f]]]).groupby('userid')[f].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['goal21'].value_counts()),\n",
    "print(train['goal22'].value_counts()),\n",
    "print(train['goal23'].value_counts()),\n",
    "print(train['goal24'].value_counts()),\n",
    "print(train['goal25'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['field12','field16']:\n",
    "    train['COUNT_{}'.format(f)] = train[f].map(pd.concat([train[f],test[f]]).value_counts())\n",
    "    test['COUNT_{}'.format(f)] = test[f].map(pd.concat([train[f],test[f]]).value_counts())\n",
    "    \n",
    "col = 'userid'\n",
    "for df in [train,test]:\n",
    "    for f in ['field26']:\n",
    "        df['{}_{}_STD'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].std())\n",
    "        df['{}_{}_MEAN'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].mean())\n",
    "        df['{}_{}_MAX'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].max())\n",
    "        \n",
    "train['ticket_price'] = train['field1'] / train['field15']\n",
    "test['ticket_price'] = test['field1'] / test['field15']\n",
    "for df in [train,test]:\n",
    "    for f in ['ticket_price']:\n",
    "        df['{}_{}_STD'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].std())\n",
    "del train['ticket_price'], test['ticket_price']\n",
    "for df in [train,test]:\n",
    "    for f in ['field0']:\n",
    "        df['{}_{}_STD'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].std())\n",
    "for df in [train,test]:\n",
    "    for f in ['field13']:\n",
    "        df['{}_{}_STD'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].std())\n",
    "for df in [train,test]:\n",
    "    for f in ['field1']:\n",
    "        df['{}_{}_MEAN'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].mean())\n",
    "for df in [train,test]:\n",
    "    for f in ['field16']:\n",
    "        df['{}_{}_MEAN'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].mean())\n",
    "        df['{}_{}_MIN'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].min())\n",
    "for df in [train,test]:\n",
    "    for f in ['field12']:\n",
    "        df['{}_{}_STD'.format(col,f)] = df[col].map(pd.concat([train[[col,f]],test[[col,f]]]).groupby(col)[f].std())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df.loc[df['field21']==2,'field2'] = df['field2'] + 12\n",
    "    df.loc[df['field21']==2,'field3'] = df['field3'] + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('tr')\n",
    "test.to_pickle('te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['goal21', 'goal22', 'goal23', 'goal24', 'goal25', 'goal1','orderid','userid']]\n",
    "\n",
    "subfor5auc = pd.read_csv('onetwotrip_challenge_sub2.csv')\n",
    "subfor5auc = subfor5auc[subfor5auc.columns[1:]]\n",
    "\n",
    "for r in [106,148,170]:\n",
    "\n",
    "    y_pred = np.zeros(test[features].shape[0])\n",
    "\n",
    "    for col in ['goal21', 'goal22', 'goal23', 'goal24', 'goal25']:\n",
    "        print(col,r)\n",
    "        train = pd.read_pickle('tr')\n",
    "        test = pd.read_pickle('te')\n",
    "\n",
    "        features = [c for c in train.columns if c not in ['goal21', 'goal22', 'goal23', 'goal24', 'goal25', 'goal1','orderid','userid']]\n",
    "\n",
    "        train = train.sort_values('goal1').reset_index(drop=True)\n",
    "        vc = train['goal1'].value_counts()\n",
    "        vc = dict(sorted(vc.items()))\n",
    "        df = pd.DataFrame()\n",
    "        train['indexcol'],i = 0,1\n",
    "        for k,v in vc.items():\n",
    "            step = train.shape[0]/v\n",
    "            indent = train.shape[0]/(v+1)\n",
    "            df2 = train[train['goal1'] == k].sample(v,random_state = r).reset_index(drop=True)\n",
    "            for j in range(0, v):\n",
    "                df2.at[j, 'indexcol'] = indent + j*step + 0.000001*i\n",
    "            df = pd.concat([df2,df])\n",
    "            i+=1\n",
    "        train = df.sort_values('indexcol', ascending=False).reset_index(drop=True)\n",
    "        del train['indexcol'], df, df2, vc\n",
    "        #for i in range(5): print(i+1,train['goal1'][i*39211:39211*(i+1)].value_counts()[1])\n",
    "\n",
    "        N=5\n",
    "        folds = KFold(n_splits=N)\n",
    "        target = train[col].copy()\n",
    "\n",
    "        lgb_param = {\n",
    "            'min_data_in_leaf': 16,\n",
    "            'num_leaves': 128, \n",
    "            'learning_rate': 0.005,\n",
    "            'min_child_weight': 0.01,\n",
    "            'bagging_fraction': 0.85, \n",
    "            'feature_fraction': 0.85,\n",
    "            'max_depth': -1,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': 1,\n",
    "            'metric':'auc',\n",
    "        }\n",
    "\n",
    "        importance = pd.DataFrame(np.zeros((train[features].shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=train[features].columns)\n",
    "        scores = []\n",
    "        oof = np.zeros(train[features].shape[0])\n",
    "\n",
    "        for fold, (trn_idx, val_idx) in enumerate(folds.split(train[features], target), 1):\n",
    "            #print('Fold {}'.format(fold))    \n",
    "            trn_data = lgb.Dataset(train[features].iloc[trn_idx, :].values, label=target.iloc[trn_idx].values)\n",
    "            val_data = lgb.Dataset(train[features].iloc[val_idx, :].values, label=target.iloc[val_idx].values)   \n",
    "            clf = lgb.train(lgb_param, trn_data, 800, valid_sets=[trn_data, val_data], verbose_eval=1001, early_stopping_rounds=1001)\n",
    "            predictions = clf.predict(train[features].iloc[val_idx, :].values) \n",
    "            importance.iloc[:, fold - 1] = clf.feature_importance()\n",
    "            oof[val_idx] = predictions\n",
    "            score = roc_auc_score(target.iloc[val_idx].values, predictions)\n",
    "            scores.append(score)\n",
    "            print('Fold {} ROC AUC Score:'.format(fold, score))\n",
    "            y_pred += clf.predict(test[features]) / N*3\n",
    "            del trn_data, val_data, predictions\n",
    "            gc.collect()\n",
    "        print(r, '######### Average ROC AUC Score {} [STD:{}]'.format(np.mean(scores), np.std(scores)))\n",
    "        gc.collect()\n",
    "    subfor5auc[col] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas.to_csv('sub2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
